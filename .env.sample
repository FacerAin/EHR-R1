# VLLM Configuration
# Directory for VLLM cache files (adjust based on available storage)
VLLM_CACHE_ROOT=/tmp/vllm_cache

# GPU memory utilization (0.0-1.0, recommended: 0.85-0.95)
VLLM_GPU_MEMORY_UTILIZATION=0.92

# HuggingFace Configuration
# Directory for HuggingFace model cache (adjust based on available storage)
HF_HOME=/tmp/huggingface_cache

# Temporary Directory Configuration
# Directory for temporary files to avoid /tmp space issues
TMPDIR=/tmp/custom_tmp

# WandB Configuration
# API key for Weights & Biases logging (get from https://wandb.ai/settings)
WANDB_API_KEY=your_wandb_api_key_here

# PyTorch CUDA Configuration
# Enable expandable memory segments to avoid fragmentation
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

# Triton Cache Configuration
# Directory for Triton kernel cache (used by DeepSpeed)
TRITON_CACHE_DIR=/tmp/triton_cache

# Model Configuration
# Default model name for evaluation
DEFAULT_MODEL_NAME=MPX0222forHF/SQL-R1-3B

# Number of GPUs for tensor parallelism
DEFAULT_TENSOR_PARALLEL_SIZE=1

# Dataset Configuration
# Path to test dataset JSON file
DEFAULT_DATASET_PATH=data/mimic_iv/test/data.json

# Path to SQLite database for execution accuracy evaluation
DEFAULT_DB_PATH=data/mimic_iv/mimic_iv.sqlite

# Output Configuration
# Directory for evaluation results
DEFAULT_OUTPUT_DIR=./results